{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/K-osA/2022S-ML/blob/main/HW4_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HW4 :: DNN**\n",
        "## 과제 목표\n",
        "* 간단한 Three Layer Network를 구현하기\n",
        "* Pytorch를 사용하여 DNN 구현 후 학습과 테스트하기\n",
        "  \n",
        "  \n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "EXvAS7OZkg_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⭐  이번 과제는 bb에 코랩 링크, ipynb 파일만 업로드합니다(HW3와 동일하게).   \n",
        "⭐  작성한 코드에 **간단한 주석을 반드시 달아주세요**!  \n",
        "⭐  코딩할 부분을 제외하고는 수정하지 마세요. 수정 시 감점입니다."
      ],
      "metadata": {
        "id": "k5IhqPYwmnUv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **문제 1 - Three Layer Network**\n",
        "```class Sigmoid```와 ```Affine```을 구현한 후 이 두 class를 사용하여 ```class ThreeLayerNet```를 완성하세요. \n",
        "* 코드 참고 : deep learning from scratch"
      ],
      "metadata": {
        "id": "OKfJ8-LiFOr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-1\n",
        "class sigmoid의 forward 함수를 구현하세요.  \n",
        "힌트) sigmoid 함수 식"
      ],
      "metadata": {
        "id": "FrrWMAJx6FUC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QSI6QIBkCPWP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        self.params = []\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "      #############################################\n",
        "      ################### 문제 1-1 #################\n",
        "      ############# sigmoid forward 구현 ###########\n",
        "      #############################################\n",
        "        # 한 줄로 구현\n",
        "        result = 1 / ( 1 + np.exp(-x)) # sigmoid 함수 식 사용\n",
        "      #############################################\n",
        "      \n",
        "        return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-2\n",
        "class Affine의 forward 함수를 구현하세요.  \n",
        "힌트) affine 함수 식"
      ],
      "metadata": {
        "id": "1YcAkmtN6UXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Affine: # Affine은 Fully Connect를 의미합니다\n",
        "    def __init__(self, W, b):\n",
        "        self.params = [W, b]\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "      #############################################\n",
        "      ################### 문제 1-2 #################\n",
        "      ############# affine forward 구현 ############\n",
        "      #############################################\n",
        "        # 코드 작성\n",
        "        out = np.dot(x, self.params[0]) + self.params[1] # W와 x를 행렬곱하고 b를 더한 것\n",
        "      #############################################\n",
        "      \n",
        "        return out\n"
      ],
      "metadata": {
        "id": "Ds05drVvG5O_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-3\n",
        "\n",
        "  각 layer의 parameter를 ```np.random.randn()``` 를 사용하여 초기화하세요.  \n",
        "  * 조건) ```class ThreeLayerNet```은 총 3개의 fully connected layer로 구성됩니다.\n",
        "  * 힌트) 차원을 잘 고려하세요. \n"
      ],
      "metadata": {
        "id": "aX3vaESK6jp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 1-4\n",
        "  문제1-1, 2에서 구현한 class를 사용하여 ThreeLayerNet의 layer를 구성하세요.\n",
        "  * 조건) ```class ThreeLayerNet```은 총 3개의 fully connected layer로 구성됩니다.\n",
        "  * 힌트) 차원을 잘 고려하세요."
      ],
      "metadata": {
        "id": "qoPlnkHg_18J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ThreeLayerNet:\n",
        "    def __init__(self, input_size, first_hidden_size, second_hidden_size, output_size):\n",
        "        I, H_1, H_2,O = input_size, first_hidden_size, second_hidden_size, output_size\n",
        "\n",
        "      #############################################\n",
        "      ################### 문제 1-3 #################\n",
        "      ######### parameter initialization ##########\n",
        "      #############################################\n",
        "        # 코드 작성\n",
        "\n",
        "        # Weight와 bias를 np.random.randn을 사용하여 임의의 값으로 초기화함.\n",
        "        # 각 size 만큼의 임의의 값이 나옴.\n",
        "        W1 = np.random.randn(I, H_1)\n",
        "        b1 = np.random.randn(H_1)\n",
        "        W2 = np.random.randn(H_1, H_2)\n",
        "        b2 = np.random.randn(H_2)\n",
        "        W3 = np.random.randn(H_2, O)\n",
        "        b3 = np.random.randn(O)\n",
        "      #########################################\n",
        "        \n",
        "\n",
        "        self.layers = [\n",
        "        #############################################\n",
        "        ################### 문제 1-4 #################\n",
        "        ############### stack layers ################\n",
        "        #############################################          \n",
        "            # 코드 작성\n",
        "            # 임의의 값으로 초기화한 Weight와 bias들을 순서대로 layer 쌓기함.\n",
        "            # 각 Affine 사이에는 sigmoid activation function을 쌓음.\n",
        "            Affine(W1, b1),\n",
        "            Sigmoid(),\n",
        "            Affine(W2, b2),\n",
        "            Sigmoid(),\n",
        "            Affine(W3, b3)\n",
        "        #############################################    \n",
        "        ]\n",
        "\n",
        "        # 모든 weight 를 담은 리스트 생성\n",
        "        self.params = []\n",
        "        for layer in self.layers:\n",
        "            self.params += layer.params\n",
        "\n",
        "    def predict(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "VmHw4K5DG3uv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dummy data로 모델 실행해보기\n",
        "x = np.random.randn(784, 100)\n",
        "model = ThreeLayerNet(100, 50, 30, 10)\n",
        "s = model.predict(x)\n",
        "print(s)"
      ],
      "metadata": {
        "id": "SNI0xGraFAAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3892a7a5-eb85-44fd-f22f-e147077826e2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-4.02741191  5.01126716  1.39342663 ...  0.52234511 -1.16723397\n",
            "   1.32095517]\n",
            " [-0.27383448  1.30966786  2.35756527 ... -2.61740502  1.70704302\n",
            "   6.76596783]\n",
            " [-1.50695557  3.06456912  4.85926306 ... -0.89517906  1.32021729\n",
            "   1.17948504]\n",
            " ...\n",
            " [-0.69909084  5.41265144  2.59607294 ... -5.08973427  1.49334975\n",
            "   6.00029458]\n",
            " [-0.44705119  3.93935546  4.5263052  ... -0.7429695   3.06631527\n",
            "   5.63307327]\n",
            " [-3.19451014  3.03714221  5.0536621  ... -0.94235929  1.22548654\n",
            "   3.92981504]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "FtZZAx7vovt4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 문제 2 - Implementing DNN using Pytorch\n",
        "문제 1에서는 Pytorch를 사용하지 않고 DNN을 구현해보았습니다.  \n",
        "문제 2에서는 Pytorch를 사용하여 DNN을 구현하고 MNIST 데이터로 분류 모델 학습을 진행합니다.\n",
        "* 코드 참고: pytorch 공식 튜토리얼"
      ],
      "metadata": {
        "id": "hOzYC0u5GfkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 importing\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "LKcI43VULpeQ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Data**"
      ],
      "metadata": {
        "id": "WCbWy3jAMGuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training data\n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True, # training data\n",
        "    download=True,\n",
        "    transform=ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# Load test data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # test data\n",
        "    download=True,\n",
        "    transform=ToTensor() # 이미지를 tensor로 변형\n",
        ")\n",
        "\n",
        "# data loader\n",
        "# train, test 각각의 data loader 생성\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=1, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "D9DqIegtLnz9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check loaded data**\n",
        "train_loader를 사용하여 하나의 데이터를 로드한 후 이 데이터가 어떤 숫자의 데이터인지 이미지로 확인해봅니다."
      ],
      "metadata": {
        "id": "QtJVlNT9A_KK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train feature와 label을 train_loader로부터 가져오기\n",
        "train_features, train_labels = next(iter(train_loader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")"
      ],
      "metadata": {
        "id": "IF90dcyJPhVw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e118a01-8103-448a-c3d8-db0a776f7a7a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([1, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지로 확인\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "00Wypwb2Pr-r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1f754356-4242-4f02-9cd3-89b6ce7c7f25"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-1\n",
        "4개의 linear layer와 3개의 ReLU layer를 가진 네트워크를 구성하세요.\n",
        "\n"
      ],
      "metadata": {
        "id": "BB_Qe54pB8_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-2\n",
        "forward 함수의 빈칸을 구현하세요."
      ],
      "metadata": {
        "id": "mK5ukeeECYJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten() # 28x28 이미지를 784 픽셀 값의 배열로 변경\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            \n",
        "            nn.Linear(in_features=28*28, out_features=512),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            #############################################\n",
        "            ################### 문제 2-1 #################\n",
        "            # 4개의 linear layer와 3개의 ReLU layer를 구성하세요\n",
        "            # (위 Linear 포함 4개, ReLU layer 포함 3개를 의미)\n",
        "            #############################################\n",
        "            \n",
        "            # 시작 차원, 끝 차원 잘 고려하여 작성하기\n",
        "            # 중간 차원은 임의로 설정 가능\n",
        "            nn.Linear(512, 256), # 주석 윗부분의 out 차원이 512이므로, 512에서 시작해서 2씩 나누면서 차원을 줄여나갔음.\n",
        "            nn.ReLU(), # Activation function으로 ReLU 사용\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10), # feature의 개수는 0부터 9까지 10개이므로 끝차원은 10임.\n",
        "            #############################################\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #############################################\n",
        "        ################### 문제 2-2 #################\n",
        "        # forward 함수 구현\n",
        "        #############################################\n",
        "        # 코드 작성\n",
        "        x = self.flatten(x) # 시작은 28*28 픽셀 이미지를 펼쳐서 1차원 784 픽셀 이미지로 만들어야 하므로 위에 정의된 flatten을 사용.\n",
        "        logits = self.linear_relu_stack(x) # 펼쳐진 784 픽셀 이미지를 layer를 stack한 곳으로 밀어넣어서 최종적으로 나온 forward 결과 값을 얻음.\n",
        "        #############################################\n",
        "        return logits # forward 결과 저장"
      ],
      "metadata": {
        "id": "zme9j_4hMiA2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cpu OR gpu 설정\n",
        "# gpu가 있을 경우, device로 cuda를 사용함\n",
        "# colab에서 '런타임 유형 변경'을 하면 gpu 사용할 수 있음\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "id": "kfBLbfwUJgtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fd73e80-2f36-400e-84e7-bb871495c3b8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device) # device로 Network 전송\n",
        "print(model) # 모델 구조 확인"
      ],
      "metadata": {
        "id": "ifGukRqQOUyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da908263-b440-429c-b0e6-da6a8ec3466a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 앞에서 출력해보았던 train_features[0](1개의 데이터)에 대해서 모델 학습 결과 확인해보기\n",
        "logits = model(train_features[0]) # 일부 백그라운드 연산들과 함께 모델의 forward 를 실행 \n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "id": "MdOf0Rd1VEi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e2f960d-9753-4961-a9e9-97cf0d53eb0e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train the Network** \n",
        "epoch과 batch를 활용하여 모델을 학습시켜 봅시다."
      ],
      "metadata": {
        "id": "J5G6rO77V7OR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 문제 2-3\n",
        "모델의 forward, backward, optimize 하는 부분을 주어진 칸에 구현하세요."
      ],
      "metadata": {
        "id": "n7RwQwKDCjOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)"
      ],
      "metadata": {
        "id": "y7jdCHQphsIO"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameter 설정\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) # optimizer\n",
        "\n",
        "n_epoch = 3 # the number of epochs\n",
        "n_batch = 32 # the number of batches"
      ],
      "metadata": {
        "id": "XGXKm0pHhnoO"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loader 설정하기\n",
        "train_loader = torch.utils.data.DataLoader(training_data, batch_size=n_batch, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=n_batch, shuffle=True)"
      ],
      "metadata": {
        "id": "s3viP29EipLg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epoch):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # input data 가져오기\n",
        "        # data 는 [inputs, labels]로 구성된 리스트\n",
        "        inputs, labels = data\n",
        "\n",
        "        # optimizer의 파라미터 gradient를 0으로 설정\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #############################################\n",
        "        ################### 문제 2-3 #################\n",
        "        # forward, backward, optimize \n",
        "        #############################################\n",
        "        # 코드 작성\n",
        "        outputs = model(inputs) # 위에서 지금까지 만들어진 NeuralNet Class를 받아와서 정의한 'model'에 inputs을 넣어서 결과값인 outputs를 도출함.(forward)\n",
        "        loss = criterion(outputs, labels) # 나온 결과값과 labels을 criterion loss function에 넣어 loss값을 얻은 후,\n",
        "        loss.backward() # backward하였음.\n",
        "        optimizer.step() # loss.backward()를 통해 도출된 각 매개에 대한 손실의 변화도에 따라\n",
        "        # 위에 정의된 SGD optimizer를 사용하여 매개들을 조정시킴.(최적화)\n",
        "        #############################################\n",
        "\n",
        "        # loss 출력\n",
        "        running_loss += loss.item()\n",
        "        if i % n_batch == 0:    # print every n_batch mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / n_batch:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "id": "m6ByMb4whKFt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66fd462-78b5-4325-a076-c22ec9d36af2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.072\n",
            "[1,    33] loss: 2.303\n",
            "[1,    65] loss: 2.300\n",
            "[1,    97] loss: 2.298\n",
            "[1,   129] loss: 2.294\n",
            "[1,   161] loss: 2.293\n",
            "[1,   193] loss: 2.288\n",
            "[1,   225] loss: 2.286\n",
            "[1,   257] loss: 2.282\n",
            "[1,   289] loss: 2.277\n",
            "[1,   321] loss: 2.272\n",
            "[1,   353] loss: 2.269\n",
            "[1,   385] loss: 2.264\n",
            "[1,   417] loss: 2.256\n",
            "[1,   449] loss: 2.252\n",
            "[1,   481] loss: 2.245\n",
            "[1,   513] loss: 2.234\n",
            "[1,   545] loss: 2.221\n",
            "[1,   577] loss: 2.216\n",
            "[1,   609] loss: 2.203\n",
            "[1,   641] loss: 2.181\n",
            "[1,   673] loss: 2.165\n",
            "[1,   705] loss: 2.146\n",
            "[1,   737] loss: 2.111\n",
            "[1,   769] loss: 2.070\n",
            "[1,   801] loss: 2.034\n",
            "[1,   833] loss: 1.991\n",
            "[1,   865] loss: 1.942\n",
            "[1,   897] loss: 1.875\n",
            "[1,   929] loss: 1.803\n",
            "[1,   961] loss: 1.689\n",
            "[1,   993] loss: 1.646\n",
            "[1,  1025] loss: 1.522\n",
            "[1,  1057] loss: 1.416\n",
            "[1,  1089] loss: 1.329\n",
            "[1,  1121] loss: 1.224\n",
            "[1,  1153] loss: 1.145\n",
            "[1,  1185] loss: 1.048\n",
            "[1,  1217] loss: 1.025\n",
            "[1,  1249] loss: 0.926\n",
            "[1,  1281] loss: 0.919\n",
            "[1,  1313] loss: 0.853\n",
            "[1,  1345] loss: 0.779\n",
            "[1,  1377] loss: 0.731\n",
            "[1,  1409] loss: 0.752\n",
            "[1,  1441] loss: 0.665\n",
            "[1,  1473] loss: 0.668\n",
            "[1,  1505] loss: 0.715\n",
            "[1,  1537] loss: 0.677\n",
            "[1,  1569] loss: 0.605\n",
            "[1,  1601] loss: 0.614\n",
            "[1,  1633] loss: 0.550\n",
            "[1,  1665] loss: 0.555\n",
            "[1,  1697] loss: 0.544\n",
            "[1,  1729] loss: 0.577\n",
            "[1,  1761] loss: 0.561\n",
            "[1,  1793] loss: 0.504\n",
            "[1,  1825] loss: 0.531\n",
            "[1,  1857] loss: 0.498\n",
            "[2,     1] loss: 0.014\n",
            "[2,    33] loss: 0.496\n",
            "[2,    65] loss: 0.501\n",
            "[2,    97] loss: 0.485\n",
            "[2,   129] loss: 0.500\n",
            "[2,   161] loss: 0.465\n",
            "[2,   193] loss: 0.480\n",
            "[2,   225] loss: 0.425\n",
            "[2,   257] loss: 0.456\n",
            "[2,   289] loss: 0.458\n",
            "[2,   321] loss: 0.443\n",
            "[2,   353] loss: 0.455\n",
            "[2,   385] loss: 0.446\n",
            "[2,   417] loss: 0.423\n",
            "[2,   449] loss: 0.411\n",
            "[2,   481] loss: 0.379\n",
            "[2,   513] loss: 0.388\n",
            "[2,   545] loss: 0.450\n",
            "[2,   577] loss: 0.387\n",
            "[2,   609] loss: 0.464\n",
            "[2,   641] loss: 0.415\n",
            "[2,   673] loss: 0.459\n",
            "[2,   705] loss: 0.408\n",
            "[2,   737] loss: 0.436\n",
            "[2,   769] loss: 0.414\n",
            "[2,   801] loss: 0.433\n",
            "[2,   833] loss: 0.403\n",
            "[2,   865] loss: 0.380\n",
            "[2,   897] loss: 0.366\n",
            "[2,   929] loss: 0.384\n",
            "[2,   961] loss: 0.360\n",
            "[2,   993] loss: 0.399\n",
            "[2,  1025] loss: 0.336\n",
            "[2,  1057] loss: 0.362\n",
            "[2,  1089] loss: 0.370\n",
            "[2,  1121] loss: 0.388\n",
            "[2,  1153] loss: 0.353\n",
            "[2,  1185] loss: 0.372\n",
            "[2,  1217] loss: 0.372\n",
            "[2,  1249] loss: 0.356\n",
            "[2,  1281] loss: 0.373\n",
            "[2,  1313] loss: 0.348\n",
            "[2,  1345] loss: 0.368\n",
            "[2,  1377] loss: 0.351\n",
            "[2,  1409] loss: 0.332\n",
            "[2,  1441] loss: 0.330\n",
            "[2,  1473] loss: 0.380\n",
            "[2,  1505] loss: 0.380\n",
            "[2,  1537] loss: 0.309\n",
            "[2,  1569] loss: 0.346\n",
            "[2,  1601] loss: 0.320\n",
            "[2,  1633] loss: 0.349\n",
            "[2,  1665] loss: 0.384\n",
            "[2,  1697] loss: 0.365\n",
            "[2,  1729] loss: 0.335\n",
            "[2,  1761] loss: 0.357\n",
            "[2,  1793] loss: 0.392\n",
            "[2,  1825] loss: 0.312\n",
            "[2,  1857] loss: 0.396\n",
            "[3,     1] loss: 0.006\n",
            "[3,    33] loss: 0.345\n",
            "[3,    65] loss: 0.354\n",
            "[3,    97] loss: 0.311\n",
            "[3,   129] loss: 0.307\n",
            "[3,   161] loss: 0.365\n",
            "[3,   193] loss: 0.320\n",
            "[3,   225] loss: 0.313\n",
            "[3,   257] loss: 0.344\n",
            "[3,   289] loss: 0.360\n",
            "[3,   321] loss: 0.369\n",
            "[3,   353] loss: 0.333\n",
            "[3,   385] loss: 0.333\n",
            "[3,   417] loss: 0.304\n",
            "[3,   449] loss: 0.320\n",
            "[3,   481] loss: 0.346\n",
            "[3,   513] loss: 0.334\n",
            "[3,   545] loss: 0.288\n",
            "[3,   577] loss: 0.252\n",
            "[3,   609] loss: 0.306\n",
            "[3,   641] loss: 0.298\n",
            "[3,   673] loss: 0.312\n",
            "[3,   705] loss: 0.368\n",
            "[3,   737] loss: 0.354\n",
            "[3,   769] loss: 0.349\n",
            "[3,   801] loss: 0.324\n",
            "[3,   833] loss: 0.314\n",
            "[3,   865] loss: 0.285\n",
            "[3,   897] loss: 0.300\n",
            "[3,   929] loss: 0.290\n",
            "[3,   961] loss: 0.265\n",
            "[3,   993] loss: 0.291\n",
            "[3,  1025] loss: 0.310\n",
            "[3,  1057] loss: 0.323\n",
            "[3,  1089] loss: 0.297\n",
            "[3,  1121] loss: 0.317\n",
            "[3,  1153] loss: 0.291\n",
            "[3,  1185] loss: 0.295\n",
            "[3,  1217] loss: 0.284\n",
            "[3,  1249] loss: 0.272\n",
            "[3,  1281] loss: 0.302\n",
            "[3,  1313] loss: 0.310\n",
            "[3,  1345] loss: 0.287\n",
            "[3,  1377] loss: 0.283\n",
            "[3,  1409] loss: 0.310\n",
            "[3,  1441] loss: 0.257\n",
            "[3,  1473] loss: 0.278\n",
            "[3,  1505] loss: 0.251\n",
            "[3,  1537] loss: 0.268\n",
            "[3,  1569] loss: 0.272\n",
            "[3,  1601] loss: 0.286\n",
            "[3,  1633] loss: 0.274\n",
            "[3,  1665] loss: 0.328\n",
            "[3,  1697] loss: 0.291\n",
            "[3,  1729] loss: 0.293\n",
            "[3,  1761] loss: 0.326\n",
            "[3,  1793] loss: 0.269\n",
            "[3,  1825] loss: 0.285\n",
            "[3,  1857] loss: 0.249\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Test the Network**"
      ],
      "metadata": {
        "id": "XnqNJjGki4JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test feature와 label을 test_loader로부터 가져오기\n",
        "test_features, test_labels = next(iter(test_loader))\n",
        "print(f\"Feature batch shape: {test_features.size()}\")\n",
        "print(f\"Labels batch shape: {test_labels.size()}\")"
      ],
      "metadata": {
        "id": "CO1AMDEAjGrK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bcb92e-265e-4351-e0a7-c1f70d0f28eb"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([32, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1개 이미지 확인해보기\n",
        "\n",
        "logits = model(test_features[0]) # 일부 백그라운드 연산들과 함께 모델의 forward 를 실행 \n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "\n",
        "\n",
        "img = test_features[0].squeeze()\n",
        "label = test_labels[0]\n",
        "\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Predicted class: {y_pred}\")\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "bgC3vITkjWdU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "3f3ce126-6448-4f37-9a4d-947f1541f762"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([0])\n",
            "Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체 test data에 대한 결과 확인\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # 모델을 학습하는 것이 아니므로 gradient 계산을 할 필요가 없음\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "id": "RE_tglcsmmRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d366763f-c488-49c1-b113-ed60317c3ba3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 92 %\n"
          ]
        }
      ]
    }
  ]
}